{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "e5d6e344-3ed7-4b0a-aa36-2b83d4842bff",
            "metadata": {},
            "source": [
                "# Train a CNN\n",
                "\n",
                "Convolutional neural networks (CNNs) are popular tools for creating automated machine learning classifiers on images or image-like samples. By converting audio into a two-dimensional frequency vs. time representation such as a spectrogram, we can generate image-like samples that can be used to train CNNs. \n",
                "\n",
                "This tutorial demonstrates the basic use of OpenSoundscape's `preprocessors` and `cnn` modules for training CNNs and making predictions using CNNs.\n",
                "\n",
                "Under the hood, OpenSoundscape uses Pytorch for machine learning tasks. By using the class `opensoundscape.ml.cnn.CNN`, you can train and predict with PyTorch's powerful CNN architectures in just a few lines of code. \n",
                "\n",
                "## Run this tutorial\n",
                "\n",
                "This tutorial is more than a reference! It's a Jupyter Notebook which you can run and modify on Google Colab or your own computer.\n",
                "\n",
                "|Link to tutorial|How to run tutorial|\n",
                "| :- | :- |\n",
                "| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kitzeslab/opensoundscape/blob/master/docs/tutorials/train_cnn.ipynb) | The link opens the tutorial in Google Colab. Uncomment the \"installation\" line in the first cell to install OpenSoundscape. |\n",
                "| [![Download via DownGit](https://img.shields.io/badge/GitHub-Download-teal?logo=github)](https://minhaskamal.github.io/DownGit/#/home?url=https://github.com/kitzeslab/opensoundscape/blob/master/docs/tutorials/train_cnn.ipynb) | The link downloads the tutorial file to your computer. Follow the [Jupyter installation instructions](https://opensoundscape.org/en/latest/installation/jupyter.html), then open the tutorial file in Jupyter. |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "b52ecca1-702b-4fa3-a48b-61025f55d8fd",
            "metadata": {},
            "outputs": [],
            "source": [
                "# if this is a Google Colab notebook, install opensoundscape in the runtime environment\n",
                "if 'google.colab' in str(get_ipython()):\n",
                "  %pip install \"opensoundscape==0.12.1\" \"jupyter-client<8,>=5.3.4\" \"ipykernel==6.17.1\"\n",
                "  num_workers=0\n",
                "else:\n",
                "  num_workers=4"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c4d88b73-77d1-4c00-a83a-8466fd79e15e",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "59c9eee8-c65c-4df1-95d0-15dda341ee0a",
            "metadata": {},
            "source": [
                "### Import needed packages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "972e3e01-c85f-415d-95cc-9b695332f738",
            "metadata": {},
            "outputs": [],
            "source": [
                "# the cnn module provides classes for training/predicting with various types of CNNs\n",
                "from opensoundscape import CNN\n",
                "\n",
                "#other utilities and packages\n",
                "import torch\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import random \n",
                "import subprocess\n",
                "from glob import glob\n",
                "import sklearn\n",
                "import os\n",
                "#set up plotting\n",
                "from matplotlib import pyplot as plt\n",
                "plt.rcParams['figure.figsize']=[15,5] #for large visuals\n",
                "%config InlineBackend.figure_format = 'retina'"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "22adf5d6-403d-4a06-bc85-477cdc60ec07",
            "metadata": {},
            "source": [
                "### Set random seeds\n",
                "\n",
                "Set manual seeds for Pytorch and Python. These essentially \"fix\" the results of any stochastic steps in model training, ensuring that training results are reproducible. You probably don't want to do this when you actually train your model, but it's useful for debugging."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "68e09bd5-e86d-44e0-8ffa-0f8ee699c31f",
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.manual_seed(0)\n",
                "random.seed(0)\n",
                "np.random.seed(0)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "82705d0a-f5f7-4104-8ea7-461ca7f72e4e",
            "metadata": {},
            "source": [
                "## Prepare audio data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "3ee65371",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/155551451.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/576585771.m4a',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5079.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5109.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5061.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/405237541.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/156094521.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5837.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5116.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/347813391.m4a',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5118.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/155551411.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/155986081.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/610787735.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/518079981.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5035.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/487421021.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/155551441.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/155997081.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/464913321.m4a',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/101775931.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/351644571.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/156002671.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/156004801.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5821.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/518079991.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5037.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/554099931.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5056.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/155971191.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/466555921.m4a',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5022.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/155988551.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5115.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/155551481.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/155551431.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5028.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/156091191.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/611565766.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5832.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/413340141.m4a',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/156092401.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5112.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/20582.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5032.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5113.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/347813351.m4a',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/574975511.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5814.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5026.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/156094711.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/156094151.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5102.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/615347576.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/155983261.wav',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/174947.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/27316.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/210212.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/27334.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/27321.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/210210.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/27368.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/210208.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/210211.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/210209.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/174950.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/210213.mp3',\n",
                            " '/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/59044.mp3']"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from opensoundscape import BoxedAnnotations\n",
                "from glob import glob\n",
                "# audio_list = os.listdir(\"Audio/Macaulay Focal Recordings\") + os.listdir(\"Audio/Xeno-canto/mp3s\")\n",
                "# len(audio_list)\n",
                "audio_list = glob(\"/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/*\") + glob(\"/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp3s/*\")\n",
                "audio_list\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "21a8c2e0",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>audio_file</th>\n",
                            "      <th>annotation_file</th>\n",
                            "      <th>annotation</th>\n",
                            "      <th>start_time</th>\n",
                            "      <th>end_time</th>\n",
                            "      <th>low_f</th>\n",
                            "      <th>high_f</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>/home/dah238/Kauai-Amakihi/Audio/Macaulay Foca...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>KAAM_song</td>\n",
                            "      <td>1.170121</td>\n",
                            "      <td>3.047612</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>/home/dah238/Kauai-Amakihi/Audio/Macaulay Foca...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>KAAM_song</td>\n",
                            "      <td>11.091803</td>\n",
                            "      <td>13.318115</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>/home/dah238/Kauai-Amakihi/Audio/Macaulay Foca...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>KAAM_song</td>\n",
                            "      <td>23.051374</td>\n",
                            "      <td>24.836450</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>/home/dah238/Kauai-Amakihi/Audio/Macaulay Foca...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>KAAM_song</td>\n",
                            "      <td>29.264000</td>\n",
                            "      <td>31.231800</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>/home/dah238/Kauai-Amakihi/Audio/Macaulay Foca...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>KAAM_song</td>\n",
                            "      <td>40.564796</td>\n",
                            "      <td>42.124980</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>441</th>\n",
                            "      <td>/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>KAAM_song</td>\n",
                            "      <td>13.322449</td>\n",
                            "      <td>13.623862</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>442</th>\n",
                            "      <td>/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>KAAM_song</td>\n",
                            "      <td>18.335950</td>\n",
                            "      <td>20.043956</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>443</th>\n",
                            "      <td>/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>KAAM_song</td>\n",
                            "      <td>20.043956</td>\n",
                            "      <td>20.475981</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>444</th>\n",
                            "      <td>/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>KAAM_call</td>\n",
                            "      <td>1.501564</td>\n",
                            "      <td>1.904121</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>445</th>\n",
                            "      <td>/home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>KAAM_call</td>\n",
                            "      <td>1.193826</td>\n",
                            "      <td>1.625972</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>446 rows Ã— 7 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                            audio_file  annotation_file  \\\n",
                            "0    /home/dah238/Kauai-Amakihi/Audio/Macaulay Foca...              NaN   \n",
                            "1    /home/dah238/Kauai-Amakihi/Audio/Macaulay Foca...              NaN   \n",
                            "2    /home/dah238/Kauai-Amakihi/Audio/Macaulay Foca...              NaN   \n",
                            "3    /home/dah238/Kauai-Amakihi/Audio/Macaulay Foca...              NaN   \n",
                            "4    /home/dah238/Kauai-Amakihi/Audio/Macaulay Foca...              NaN   \n",
                            "..                                                 ...              ...   \n",
                            "441  /home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp...              NaN   \n",
                            "442  /home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp...              NaN   \n",
                            "443  /home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp...              NaN   \n",
                            "444  /home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp...              NaN   \n",
                            "445  /home/dah238/Kauai-Amakihi/Audio/Xeno-canto/mp...              NaN   \n",
                            "\n",
                            "    annotation  start_time   end_time  low_f  high_f  \n",
                            "0    KAAM_song    1.170121   3.047612    NaN     NaN  \n",
                            "1    KAAM_song   11.091803  13.318115    NaN     NaN  \n",
                            "2    KAAM_song   23.051374  24.836450    NaN     NaN  \n",
                            "3    KAAM_song   29.264000  31.231800    NaN     NaN  \n",
                            "4    KAAM_song   40.564796  42.124980    NaN     NaN  \n",
                            "..         ...         ...        ...    ...     ...  \n",
                            "441  KAAM_song   13.322449  13.623862    NaN     NaN  \n",
                            "442  KAAM_song   18.335950  20.043956    NaN     NaN  \n",
                            "443  KAAM_song   20.043956  20.475981    NaN     NaN  \n",
                            "444  KAAM_call    1.501564   1.904121    NaN     NaN  \n",
                            "445  KAAM_call    1.193826   1.625972    NaN     NaN  \n",
                            "\n",
                            "[446 rows x 7 columns]"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "annotations_df = pd.concat([\n",
                "    pd.read_csv(\"/home/dah238/Kauai-Amakihi/Annotations/macaulay/combined_output_macaulay_v2.csv\"),\n",
                "    pd.read_csv(\"/home/dah238/Kauai-Amakihi/Annotations/xeno_canto/combined_output_xeno_canto.csv\")\n",
                "], ignore_index=True)\n",
                "annotationsfull = BoxedAnnotations(df= annotations_df,audio_files = audio_list)\n",
                "annotationsfull"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "00072b61",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Warning: Xing stream size off by more than 1%, fuzzy seeking may be even more fuzzy than by design!\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "%%capture\n",
                "# Parameters to use for label creation\n",
                "clip_duration = 3\n",
                "clip_overlap = 1.5\n",
                "min_label_overlap = 0.25\n",
                "species_of_interest = [\"KAAM\"]\n",
                "\n",
                "# Create dataframe of one-hot labels\n",
                "clip_labels = annotationsfull.clip_labels(\n",
                "    clip_duration = clip_duration, \n",
                "    clip_overlap = clip_overlap,\n",
                "    min_label_overlap = min_label_overlap,\n",
                "    # class_subset = species_of_interest # You can comment this line out if you want to include all species.\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "186bb611",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "64"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "clip_labels.reset_index()[\"file\"].nunique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "c6d0f615",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(2300, 10)"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "clip_labels.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fb6f3bc5",
            "metadata": {},
            "source": [
                "This is the way to do it without including blank audio files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "89864936",
            "metadata": {},
            "outputs": [],
            "source": [
                "# clip_labels = pd.read_csv(\"Annotations/lables_3sec_experiment1.csv\",index_col=[0,1,2])[[\"KAAM_song\"]]\n",
                "# clip_labels = clip_labels.reset_index()\n",
                "# clip_labels[\"file\"]=clip_labels[\"file\"].str.replace(\" (GIT)\",\"\")\n",
                "# clip_labels = clip_labels.set_index([\"file\",\"start_time\",\"end_time\"])\n",
                "# clip_labels"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d7ec6fac-fb79-43dc-86c9-d66230189a94",
            "metadata": {},
            "source": [
                "## Create train, validation, and test datasets\n",
                "\n",
                "To train and test a model, we use three datasets:\n",
                "\n",
                "* The **training dataset** is used to fit your machine learning model to the audio data. \n",
                "* The **validation dataset** is a held-out dataset that is used to select hyperparameters (e.g. how many epochs to train for) during training\n",
                "* The **test dataset** is another held-out dataset that we use to check how the model performs on data that were not available at all during training.\n",
                "\n",
                "While both the training and validation datasets are used while training the model, the test dataset is never touched until the model is fully trained and completed.\n",
                "\n",
                "The training and validation datasets may be gathered from the same source as each other. In contrast, the test dataset is often gathered from a different source to assess whether the model's performance generalizes to a real-world problem. For example, training and validation data might be drawn from an online database like Xeno-Canto, whereas the testing data is from your own field data. \n",
                "\n",
                "### Create a test dataset\n",
                "\n",
                "We'll separate the test dataset first. For a good assessment of the model's generalization, we want the test set to be independent of the training and validation datasets. For example, we don't want to use clips from the same source recording in the training dataset and the test dataset.\n",
                "\n",
                "For this example, we'll use the recordings in the folders `Recording_1`, `Recording_2` and `Recording_3` as our training and validation data, and use the recordings in folder `Recording_4` as our test data. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "d8190cbf-d9ad-400d-ad44-789eead2a656",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "((1840, 10), (460, 10))"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "train_df, val_df = train_test_split(clip_labels,test_size=0.2)\n",
                "train_df.shape,val_df.shape\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "afb99584-33fc-4889-83b5-4c912e3c3188",
            "metadata": {},
            "source": [
                "### Split training and validation datasets\n",
                "\n",
                "Now, separate the remaining non-test data into training and validation datasets.\n",
                "\n",
                "The idea of keeping a separate validation dataset is that, throughout training, we can 'peek' at the performance on the validation set to choose hyperparameters. (This is in contrast to the test dataset, which we will not look at until we've finished training our model.)\n",
                "\n",
                "One important hyperparameter is the number of **epochs** to train to, in order to prevent overfitting. Each epoch includes one round of fitting on each training sample. \n",
                "\n",
                "If a model's performance on a training dataset continues to improve as it trains, but its performance on the validation dataset plateaus, this could incate the model is **overfitting** on the training dataset, learning information specific to those particular samples instead of gaining the ability to generalize to new data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "2f47db9c-bf65-46b9-b64b-040d13ea17e1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Split our training data into training and validation sets\n",
                "# train_df, valid_df = sklearn.model_selection.train_test_split(\n",
                "#     train_and_val_set, test_size=0.1, random_state=0\n",
                "# )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "74268296-4323-46c5-8a47-9f343f77844f",
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df.to_csv(\"Experiment2(Full_Focal)/train_set.csv\")\n",
                "val_df.to_csv(\"Experiment2(Full_Focal)/valid_set.csv\")\n",
                "#look back to reorganize file save locations, EDIT THIS EVERY EXPERIMENT"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "21d30e3e-eda1-4476-8ebf-db4b0844a1d0",
            "metadata": {},
            "source": [
                "### Resample data for even class representation\n",
                "\n",
                "Before training, we will balance the number of samples of each class in the training set. This helps the model learn all of the classes, rather than paying too much attention to the classes with the most labeled annotations. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "27d518a4",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "KAAM_song\n",
                            "False    1193\n",
                            "True      647\n",
                            "Name: count, dtype: int64"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train_df.KAAM_song.value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "5a75f8ae-c81b-4a1b-b62e-87fe1b64eca0",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "KAAM_song\n",
                            "False    6304\n",
                            "True      903\n",
                            "Name: count, dtype: int64"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from opensoundscape.data_selection import resample\n",
                "\n",
                "# upsample (repeat samples) so that all classes have 800 samples\n",
                "balanced_train_df = resample(train_df, n_samples_per_class=636, random_state=0)\n",
                "balanced_train_df.KAAM_song.value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a9730295-df2d-4fca-85d8-a7d756b1763f",
            "metadata": {},
            "source": [
                "## Set up model\n",
                "\n",
                "Now we create a model object. We have to select several parameters when creating this object: its `architecture`, `classes`, and `sample_duration`. \n",
                "\n",
                "Some additional parameters can also be changed at this step, such as the preprocessor used to create spectrograms and the shape of the spectrograms. \n",
                "\n",
                "For more detail on this step, see the [\"Customize CNN training\"](\"tutorials/CNN.html\") tutorial.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fe66d592-fb5b-4e9d-a832-9ae123b9a442",
            "metadata": {},
            "source": [
                "### Create CNN object"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2c5061ad-3fae-4b00-967e-f1101ff5165e",
            "metadata": {},
            "source": [
                "Now, create a CNN object with this architecture, the classes we put into the dataframe above, and the same sample duration as we selected above.\n",
                "\n",
                "The first time you run this script for a particular architecture, OpenSoundscape will download the desired architecture."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "c61f98fb-0791-4e3d-ab51-ee36ae3e1dd5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a CNN object designed to recognize 3-second samples\n",
                "from opensoundscape import CNN\n",
                "\n",
                "# Use resnet34 architecture\n",
                "architecture = \"resnet18\"\n",
                "\n",
                "# Can use this code to get your classes, if needed\n",
                "class_list = list(train_df.columns)\n",
                "clip_duration = 3\n",
                "\n",
                "model = CNN(\n",
                "    architecture=architecture,\n",
                "    classes=class_list,\n",
                "    sample_duration=clip_duration,  # 3s, selected above\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f92a8de1-3d6b-4f03-bd61-dae8c17f1ddf",
            "metadata": {},
            "source": [
                "### Check model device\n",
                "\n",
                "If a GPU is available on your computer, the CNN object automatically selects it for accellerating performance. You can override `.device` to use a specific device such as `cpu` or `cuda:3`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "9de0c6df-d999-4791-b358-312a076f6888",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "model.device is: cuda:0\n"
                    ]
                }
            ],
            "source": [
                "print(f\"model.device is: {model.device}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2c901111-323f-485d-bb45-f97a8abedafb",
            "metadata": {},
            "source": [
                "### Set up WandB model logging\n",
                "\n",
                "While this step is optional, it is very helpful for model training. In this step, we set up model logging on a service called **Weights & Biases** (AKA WandB). \n",
                "\n",
                "Weights & Biases is a free website you can use to monitor model training. It is integrated with OpenSoundscape to include helpful functions such as checking on your model's training progress in real time, visualizing the spectrograms created for training your model, comparing multiple tries at training the same model, and more. For more information, check out this [blog post](https://wandb.ai/wandb_fc/repo-spotlight/reports/Community-Spotlight-OpenSoundscape--Vmlldzo0MDcwMTI4). \n",
                "\n",
                "The instructions below will help you set up `wandb` logging:\n",
                "\n",
                "* Create an account on the [Weights and Biases website](https://wandb.ai/). \n",
                "* The first time you use `wandb`, you'll need to run `wandb.login()` in Python or `wandb login` on the command line, then enter the API key from your [settings](https://wandb.ai/settings) page\n",
                "* In a Python script where you want to log model training, use `wandb.init()` as demonstrated below. The \"Entity\" or team option allows runs and projects to be shared across members in a group, making it easy to collaborate and see progress of other team members' runs.\n",
                "\n",
                "\n",
                "As training progresses, performance metrics will be plotted to the wandb logging platform and visible on this run's web page. For example, this [wandb web page](https://wandb.ai/kitzeslab/opensoundscape%20training%20demo/runs/w1xyk7zr/workspace?workspace=user-samlapp) shows the content logged to wandb when this notebook was run by the Kitzes Lab. By default, OpenSoundscape + WandB integration creates several pages with information about the model:\n",
                "\n",
                "- Overview: hyperparameters, run description, and hardware available during the run\n",
                "- Charts: \"Samples\" panel with audio and images of preprocessed samples (useful for checking that your preprocessing performs as expected and your labels are correct)\n",
                "- Charts: graphs of each class's performance metrics over training time\n",
                "- Model: summary of model architecture\n",
                "- Logs: standard output of training script\n",
                "- System: computational performance metrics including memory, CPU use, etc\n",
                "\n",
                "When training several models and comparing performance, the \"Project\" page of WandB provides comparisons of metrics and hyperparameters across training runs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "113a1a3c-1b0b-4159-83d7-43f7cc1a0d24",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhindsdavis2\u001b[0m (\u001b[33mkitzeslab\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/wandb/analytics/sentry.py:263: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
                        "  self.scope.user = {\"email\": email}\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/wandb/analytics/sentry.py:263: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
                        "  self.scope.user = {\"email\": email}\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.22.3"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>/home/dah238/Kauai-Amakihi/wandb/run-20251119_141442-asgqat06</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Syncing run <strong><a href='https://wandb.ai/kitzeslab/KAAM%20/runs/asgqat06' target=\"_blank\">genial-sun-7</a></strong> to <a href='https://wandb.ai/kitzeslab/KAAM%20' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/kitzeslab/KAAM%20' target=\"_blank\">https://wandb.ai/kitzeslab/KAAM%20</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/kitzeslab/KAAM%20/runs/asgqat06' target=\"_blank\">https://wandb.ai/kitzeslab/KAAM%20/runs/asgqat06</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "import wandb\n",
                "\n",
                "try:\n",
                "    wandb.login()\n",
                "    wandb_session = wandb.init(\n",
                "        entity=\"kitzeslab\",  # replace with your entity/group name\n",
                "        project=\"KAAM \",\n",
                "        name=None,\n",
                "    )\n",
                "except:  # if wandb.init fails, don't use wandb logging\n",
                "    # raise\n",
                "    print(\"failed to create wandb session. wandb session will be None\")\n",
                "    wandb_session = None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "bcb8c2cd",
            "metadata": {},
            "outputs": [],
            "source": [
                "# wandb_session = None"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f865c2ff-441b-40eb-a6d9-7665452c5add",
            "metadata": {},
            "source": [
                "## Train the CNN\n",
                "\n",
                "Finally, train the CNN for two epoch. Typically, we would train the model for more than two epochs, but because training is slow and is much better done outside of a Jupyter Notebook, we just include this as a short demonstration of training.\n",
                "\n",
                "Each **epoch** is one pass-through of all of the samples in the training dataset, plus running predictions on the validation dataset. \n",
                "\n",
                "Each epoch is composed of smaller groups of samples called **batches**. The machine learning model predicts on every sample in the batch, then the model weights are updated based on those samples. Larger batches can increase training speed, but require more memory. If you get a memory error, try reducing the batch size.\n",
                "\n",
                "We use default training parameters, but many aspects of CNN training can be customized (see the \"Customize CNN training\" tutorial for examples)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "981bffa6-842e-4e76-bbf1-ad92a3a72dee",
            "metadata": {},
            "outputs": [],
            "source": [
                "checkpoint_folder = Path(\"Experiment2(Full_Focal)/checkpoints\")\n",
                "checkpoint_folder.mkdir(exist_ok=True)\n",
                "#CHANGE CHECKPOINT FOLDER PATH"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "7f9fedb0",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th>KAAM_song</th>\n",
                            "      <th>KAAM_call</th>\n",
                            "      <th>?_KAAM_call</th>\n",
                            "      <th>KAAM_song</th>\n",
                            "      <th>?_KAAM_song</th>\n",
                            "      <th>?</th>\n",
                            "      <th>?KAAM_call</th>\n",
                            "      <th>?KAAM_song</th>\n",
                            "      <th>?_KAAM_song</th>\n",
                            "      <th>KAAM_wsong</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>file</th>\n",
                            "      <th>start_time</th>\n",
                            "      <th>end_time</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5837.wav</th>\n",
                            "      <th>16.5</th>\n",
                            "      <th>19.5</th>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/156091191.wav</th>\n",
                            "      <th>1.5</th>\n",
                            "      <th>4.5</th>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5102.wav</th>\n",
                            "      <th>456.0</th>\n",
                            "      <th>459.0</th>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/156002671.wav</th>\n",
                            "      <th>196.5</th>\n",
                            "      <th>199.5</th>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal Recordings/5832.wav</th>\n",
                            "      <th>73.5</th>\n",
                            "      <th>76.5</th>\n",
                            "      <td>True</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                                        KAAM_song  \\\n",
                            "file                                               start_time end_time              \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 16.5       19.5           True   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 1.5        4.5            True   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 456.0      459.0          True   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 196.5      199.5          True   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 73.5       76.5           True   \n",
                            "\n",
                            "                                                                        KAAM_call  \\\n",
                            "file                                               start_time end_time              \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 16.5       19.5          False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 1.5        4.5           False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 456.0      459.0         False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 196.5      199.5         False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 73.5       76.5          False   \n",
                            "\n",
                            "                                                                        ?_KAAM_call  \\\n",
                            "file                                               start_time end_time                \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 16.5       19.5            False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 1.5        4.5             False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 456.0      459.0           False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 196.5      199.5           False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 73.5       76.5            False   \n",
                            "\n",
                            "                                                                         KAAM_song  \\\n",
                            "file                                               start_time end_time               \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 16.5       19.5           False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 1.5        4.5            False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 456.0      459.0          False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 196.5      199.5          False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 73.5       76.5           False   \n",
                            "\n",
                            "                                                                        ?_KAAM_song  \\\n",
                            "file                                               start_time end_time                \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 16.5       19.5            False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 1.5        4.5             False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 456.0      459.0           False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 196.5      199.5           False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 73.5       76.5            False   \n",
                            "\n",
                            "                                                                            ?  \\\n",
                            "file                                               start_time end_time          \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 16.5       19.5      False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 1.5        4.5       False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 456.0      459.0     False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 196.5      199.5     False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 73.5       76.5      False   \n",
                            "\n",
                            "                                                                        ?KAAM_call  \\\n",
                            "file                                               start_time end_time               \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 16.5       19.5           False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 1.5        4.5            False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 456.0      459.0          False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 196.5      199.5          False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 73.5       76.5           False   \n",
                            "\n",
                            "                                                                        ?KAAM_song  \\\n",
                            "file                                               start_time end_time               \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 16.5       19.5           False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 1.5        4.5            False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 456.0      459.0          False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 196.5      199.5          False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 73.5       76.5           False   \n",
                            "\n",
                            "                                                                          ?_KAAM_song  \\\n",
                            "file                                               start_time end_time                  \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 16.5       19.5              False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 1.5        4.5               False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 456.0      459.0             False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 196.5      199.5             False   \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 73.5       76.5              False   \n",
                            "\n",
                            "                                                                        KAAM_wsong  \n",
                            "file                                               start_time end_time              \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 16.5       19.5           False  \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 1.5        4.5            False  \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 456.0      459.0          False  \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 196.5      199.5          False  \n",
                            "/home/dah238/Kauai-Amakihi/Audio/Macaulay Focal... 73.5       76.5           False  "
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "balanced_train_df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "b51235f6",
            "metadata": {},
            "outputs": [],
            "source": [
                "model.device = \"cuda:1\"\n",
                "#changing to other snowy gpu *temp"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "2ea86e7f-5533-4815-bf34-31e141002dd2",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 0\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4d086133ef134c00a487eaa9e91aba9b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 0 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.784\n",
                        "\tMost Recent Batch Loss: 0.784\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 0 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.257\n",
                        "\tMost Recent Batch Loss: 0.161\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e161e25bc0884c6dbd5db8f82278fc8c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 1\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b4ee04c8345b46c29daaa61461c7f9ba",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 1 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.147\n",
                        "\tMost Recent Batch Loss: 0.147\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 1 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.121\n",
                        "\tMost Recent Batch Loss: 0.086\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ca0daa8c52d64e08827d6ea89d42be6a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 2\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d9dfd6d794f64095a1f2b71cec75d599",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 2 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.094\n",
                        "\tMost Recent Batch Loss: 0.094\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 2 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.079\n",
                        "\tMost Recent Batch Loss: 0.054\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "99e69f6e7ce7459895584d9a6c51e5f7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 3\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "72c617c52f7146dcbcb5f036d5855123",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 3 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.075\n",
                        "\tMost Recent Batch Loss: 0.075\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 3 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.060\n",
                        "\tMost Recent Batch Loss: 0.055\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bf1cefee3e174598985531d47ddc1f34",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 4\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f7c7fd6f2f034a309f859ecfcc8a1ea8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 4 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.042\n",
                        "\tMost Recent Batch Loss: 0.042\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 4 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.050\n",
                        "\tMost Recent Batch Loss: 0.037\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2d143c45d80347cdb163e5f804888577",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 5\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3aa3e69b1c7b448194cbf3b88e10c4dd",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 5 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.033\n",
                        "\tMost Recent Batch Loss: 0.033\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 5 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.040\n",
                        "\tMost Recent Batch Loss: 0.033\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7da4531bc1ec452c826035815a47eafe",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 6\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "94d6f2604b7847ebb672336d738a79bb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 6 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.052\n",
                        "\tMost Recent Batch Loss: 0.052\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 6 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.036\n",
                        "\tMost Recent Batch Loss: 0.042\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "cfb41c0a11ef4448ab84468913c8bc7b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 7\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ac6b49c693c64f91ae7c594c7537443f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 7 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.038\n",
                        "\tMost Recent Batch Loss: 0.038\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 7 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.031\n",
                        "\tMost Recent Batch Loss: 0.035\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8e1d8913cd154790af98e55ec5f2ce18",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 8\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e65cd8c23c41417ca9141d8874b6bbaf",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 8 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.022\n",
                        "\tMost Recent Batch Loss: 0.022\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 8 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.028\n",
                        "\tMost Recent Batch Loss: 0.026\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a0cdaba48edc4458b9df0b7a13dee339",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 9\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "23482dd41c1f4cae8c1ff538ac4dc715",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 9 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.018\n",
                        "\tMost Recent Batch Loss: 0.018\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 9 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.026\n",
                        "\tMost Recent Batch Loss: 0.037\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5e4554eee1eb4085bb1292f7f319d22c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 10\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b4583334a2974adca4781b9ca982f4f0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 10 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.029\n",
                        "\tMost Recent Batch Loss: 0.029\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 10 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.023\n",
                        "\tMost Recent Batch Loss: 0.016\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "17f91e7ad8f04948aafb3f8bd5ff9e1b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 11\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bda80de9310e457385e50cee3662dfee",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 11 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.023\n",
                        "\tMost Recent Batch Loss: 0.023\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 11 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.021\n",
                        "\tMost Recent Batch Loss: 0.017\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "07359711437247f4b6dd6c0e436d926f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 12\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6a286e2fd46f48139b2588d0aa108cac",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 12 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.016\n",
                        "\tMost Recent Batch Loss: 0.016\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 12 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.020\n",
                        "\tMost Recent Batch Loss: 0.021\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6c0b1cc8daea40548f986f371453258c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 13\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e01ba93c4e0c4385a8752050d015b781",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 13 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.024\n",
                        "\tMost Recent Batch Loss: 0.024\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 13 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.021\n",
                        "\tMost Recent Batch Loss: 0.045\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4db95b2f6dc44ea8997d940c1af49e8e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 14\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3699f90ca8ad4730828421e72cd6fcef",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 14 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.020\n",
                        "\tMost Recent Batch Loss: 0.020\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 14 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.019\n",
                        "\tMost Recent Batch Loss: 0.029\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6c1b278e2d9f4b329465203fea85a69d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 15\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3d1bd186c7b449af8f747c7e3907cdf0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 15 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.020\n",
                        "\tMost Recent Batch Loss: 0.020\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 15 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.018\n",
                        "\tMost Recent Batch Loss: 0.014\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "03516e1251744a3c9a3b7517331c77cb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 16\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "041b75ff6bd0474e9fa2735073aab01a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 16 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.026\n",
                        "\tMost Recent Batch Loss: 0.026\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 16 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.017\n",
                        "\tMost Recent Batch Loss: 0.019\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1062cfebf79d469badfca6b41cc32c0e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 17\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8ba7e55bb96543dab0423275a4b55734",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 17 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.017\n",
                        "\tMost Recent Batch Loss: 0.017\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 17 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.017\n",
                        "\tMost Recent Batch Loss: 0.012\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "feca6fab535b43f8ab0dc9e6f47a690e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 18\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "20b65e2d6ae04eb488020f84034e0641",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 18 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.024\n",
                        "\tMost Recent Batch Loss: 0.024\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 18 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.015\n",
                        "\tMost Recent Batch Loss: 0.012\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ca3e42a2ade94e85acb3520200f221f4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 19\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "77442ce634954b9ba0a05f8c1799b1f7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 19 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.017\n",
                        "\tMost Recent Batch Loss: 0.017\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 19 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.016\n",
                        "\tMost Recent Batch Loss: 0.012\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "887b5bfc635f47948bcacf57c3147469",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 20\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e28a0cac3f82411fb8b07d1ad161e6e8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 20 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.013\n",
                        "\tMost Recent Batch Loss: 0.013\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 20 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.015\n",
                        "\tMost Recent Batch Loss: 0.024\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "575fdfe18e044a709520ae887a0f4339",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 21\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2e3797f8567049a19592b5b0e8d72311",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 21 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.012\n",
                        "\tMost Recent Batch Loss: 0.012\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 21 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.015\n",
                        "\tMost Recent Batch Loss: 0.034\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d65ebc98b1bf4f1ebdde1bd2430217f5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 22\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "463514859d5a4574b381cf527174ac76",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 22 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.015\n",
                        "\tMost Recent Batch Loss: 0.015\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 22 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.014\n",
                        "\tMost Recent Batch Loss: 0.018\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "630e7c645fda4edab21ed4f5b4f274ce",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 23\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b5083bef1f4a44d3bbe543685469bd16",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 23 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.014\n",
                        "\tMost Recent Batch Loss: 0.014\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 23 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.013\n",
                        "\tMost Recent Batch Loss: 0.013\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8f70860078c34eae9cf83f5bee64133e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 24\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b0e542a0a6b748d8baed1c6b46581b2c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 24 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.011\n",
                        "\tMost Recent Batch Loss: 0.011\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 24 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.014\n",
                        "\tMost Recent Batch Loss: 0.011\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "62388034d3f84832b5a9d28e78ac4bc3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 25\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1fdd2ec1e8a64f8dbc34bc73d1f641b5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 25 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.007\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 25 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.013\n",
                        "\tMost Recent Batch Loss: 0.018\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "dc1e84ccfa034e3fbe9a042d437c5e09",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 26\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6f94ddbbee1e48f198632aaab8935b45",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 26 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.013\n",
                        "\tMost Recent Batch Loss: 0.013\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 26 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.013\n",
                        "\tMost Recent Batch Loss: 0.007\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4ea260b596c241e496baeda36df0a24a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 27\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1c4f879d40de4cde958a393f663a9a2c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 27 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.019\n",
                        "\tMost Recent Batch Loss: 0.019\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 27 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.013\n",
                        "\tMost Recent Batch Loss: 0.008\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "00c91d8ac23a4461ab18935c1b76f973",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 28\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a6b7ba6c5b574a89a9f6245851625cdb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 28 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.013\n",
                        "\tMost Recent Batch Loss: 0.013\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 28 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.014\n",
                        "\tMost Recent Batch Loss: 0.014\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ac725f1195b04c5ea37b05b7809bb4ec",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 29\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "174c7f7ff3d94e288faf9223e1e3a420",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 29 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.011\n",
                        "\tMost Recent Batch Loss: 0.011\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 29 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.012\n",
                        "\tMost Recent Batch Loss: 0.016\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "985b175fb55d4217a5633338ef5a6b78",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 30\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ec509b51c90a4e289ae3791d9c854df4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 30 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.013\n",
                        "\tMost Recent Batch Loss: 0.013\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 30 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.012\n",
                        "\tMost Recent Batch Loss: 0.012\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6ae4f1415adb4429bae0080e334ddbbb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 31\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c1020b3f2e2f4767aedf942f32b09055",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 31 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.020\n",
                        "\tMost Recent Batch Loss: 0.020\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 31 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.011\n",
                        "\tMost Recent Batch Loss: 0.005\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4a4e03099f6f445d8edc51dbc147fbdb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 32\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a86c3de5adbc43f18bd150e0b29c61eb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 32 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.007\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 32 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.011\n",
                        "\tMost Recent Batch Loss: 0.010\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "553bbba66d0040de88a918faa64d65ba",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 33\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ec6f70a4eb2d47c0b31746873de4047c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 33 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.007\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 33 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.011\n",
                        "\tMost Recent Batch Loss: 0.006\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "11871107addf40478f4e149380d176e0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 34\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9fbb5fcf56304dbeb7d4790e6d9e3f31",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 34 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.008\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 34 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.010\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8bc74c02cd6b4202a8ec09a8d380a2fe",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 35\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c9f93e25260d4996a9489c37719c6e8c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 35 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.010\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 35 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.011\n",
                        "\tMost Recent Batch Loss: 0.011\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ec0ca20838d74ebaa8429a720cc50453",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 36\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1342748a11f94677b0a481d3f772d9ee",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 36 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.006\n",
                        "\tMost Recent Batch Loss: 0.006\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 36 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.011\n",
                        "\tMost Recent Batch Loss: 0.018\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "df8062d583c84cc89f6a305bca85166c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 37\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bc67460d705a406abfd77d92c7014e51",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 37 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.006\n",
                        "\tMost Recent Batch Loss: 0.006\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 37 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.008\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1ce9f1539cfa4e9cbac5f99a3bf7266d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 38\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1e903bb2f3774fdd830fb2962d5cfd23",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 38 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.005\n",
                        "\tMost Recent Batch Loss: 0.005\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 38 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.011\n",
                        "\tMost Recent Batch Loss: 0.007\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8d114603557e4cd2bed392f1cf81ccf3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 39\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f2ec4d71af2c4f9693a20756f70ad7e9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 39 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.003\n",
                        "\tMost Recent Batch Loss: 0.003\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 39 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.006\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "53d6e301414c4d3386692bef557fbc22",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 40\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1f81bb3cff7d4b988912a052c95650f2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 40 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.010\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 40 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.018\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9e4bb2adf35b4108b00763061827822f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 41\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4ccb0c945b3b4e3fb412fe23abb1652f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 41 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.006\n",
                        "\tMost Recent Batch Loss: 0.006\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 41 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.015\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e59bf4aa79634593a0f5f4f49b46b800",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 42\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "cd3c3c424c144206817b828c399cefa2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 42 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.009\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 42 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.007\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f6214a9ed13f4edda17a33bfc4d3f5b7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 43\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6fe1a0dd98b545b4a5421019ace67057",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 43 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.005\n",
                        "\tMost Recent Batch Loss: 0.005\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 43 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.017\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "fcc59f41e9654c1a97e2bbffb605d2bc",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 44\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1cd3335041444f699be6a46c835eec64",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 44 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.012\n",
                        "\tMost Recent Batch Loss: 0.012\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 44 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.005\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "02380fd0a39849eb8efb1af5194ef8a0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 45\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5545ecff02f64c67a81b683dec80eee8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 45 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.006\n",
                        "\tMost Recent Batch Loss: 0.006\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 45 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.012\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9740a62250ec45bb9f40eeb18cf3c0e7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 46\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "446c85c0841640e8aa04e00efb676052",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 46 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.004\n",
                        "\tMost Recent Batch Loss: 0.004\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 46 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.004\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "77d73a2a5927460a87a196aa5c7c7cee",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 47\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "386752b231414c3cb6dc740acce7523b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 47 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.011\n",
                        "\tMost Recent Batch Loss: 0.011\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 47 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.007\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b01f42a9539e4483a74968d775e068d3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 48\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "32b1d266df4641f1a0676c6ceab3ce7b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 48 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.009\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 48 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.009\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "16a0f3a433fb45a28dc039cc8015a29b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 49\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "df38f358a3994816a64866a0305cefe9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 49 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.012\n",
                        "\tMost Recent Batch Loss: 0.012\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 49 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.007\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2d52c1184a0f48a6b89393d0f72f3292",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 50\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2e40ab68ac934a96bd9f063aa8e30218",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 50 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.007\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 50 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.004\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6178d8bef3d24ea886457d967396e5f7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 51\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b8e887be41ec4aa6a36eea46fca56410",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 51 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.006\n",
                        "\tMost Recent Batch Loss: 0.006\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 51 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.014\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ff8febfec71144e499db2d3cb219a843",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 52\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "72ecd4e485274cf5a204d7b794083039",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 52 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.011\n",
                        "\tMost Recent Batch Loss: 0.011\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 52 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.008\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6333a3fd3e674e1fa4e34ee4595f12c2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 53\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7588daed5f644f1cbe269e71cf0c025c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 53 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.007\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 53 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.007\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a79df0d2b7654774913783b3e475ea36",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 54\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "752bc3ea732a45faa90d691ad07d64e1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 54 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.011\n",
                        "\tMost Recent Batch Loss: 0.011\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 54 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.005\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d486ca77eebe45d0b95edb6336262eeb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 55\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6a1216d4c99248c095a555d50ede2a3c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 55 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.014\n",
                        "\tMost Recent Batch Loss: 0.014\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 55 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.006\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "cd63b96223d243b7952df7ef6816f1aa",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 56\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "128fdb7cd3054a078ab3126ce9d021cf",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 56 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.004\n",
                        "\tMost Recent Batch Loss: 0.004\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 56 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.008\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5f0966c2a8c44853b37b19acffc89486",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 57\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a0bafcaf272247da970f9c7d2349117b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 57 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.010\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 57 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.006\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c2e9b61b91f0469da6cf4172c58b56f6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 58\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d8be299e1c7e46cb9eaeae7efe435e14",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 58 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.014\n",
                        "\tMost Recent Batch Loss: 0.014\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 58 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.015\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "667e78a566a3487da9a4df10249fdecd",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 59\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c72d9a004eba42bbb2ecc5dea9fe6aa5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 59 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.010\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 59 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.004\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4983bfff3220476eac7e3c6c03192eae",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 60\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4a3b29bcbae6476eb8f5ba0cd618a48a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 60 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.010\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 60 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.003\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f9606a7e53964a50bdb5b436c06e90b7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 61\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "dacf6e97b1b845d390333d0282d80fdf",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 61 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.010\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 61 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.014\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b65c12f4eca4492eab15fc23805cb38a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 62\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e99549f6398246629dd59f7b0fe6445d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 62 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.008\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 62 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.008\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "292b01be465641f4a64f47c1bf260f90",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 63\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "81edd68cc24f46a28d91e700109894f6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 63 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.006\n",
                        "\tMost Recent Batch Loss: 0.006\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 63 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.011\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "93f8f44878d344f2a7ab4e0e76c17fed",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 64\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1a41a659e49e43c6a620991221191b7e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 64 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.007\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 64 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.005\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "cceaab40a45442928a86883d714bd480",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 65\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "79d6225d0e8c4fceaa2885af02772f15",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 65 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.006\n",
                        "\tMost Recent Batch Loss: 0.006\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 65 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.011\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "11a70626b9d648b1a2edc002c98ba129",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 66\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c816e7e0ef714061a8f15de642ca0083",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 66 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.008\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 66 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.007\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "43b46c148bf645b59097881c834db67c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 67\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3452ec8c50ae47c6a0dd62b224373452",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 67 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.009\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 67 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.005\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "99a2438844b34985aca94039b9826a03",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 68\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7e9505b7a4454a2298cfa4cefe1686fe",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 68 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.003\n",
                        "\tMost Recent Batch Loss: 0.003\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 68 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.008\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f5bb60e3f05e46da81dc04603886feaa",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 69\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "27e916b0cd7d4c0994a32125aa32917e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 69 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.006\n",
                        "\tMost Recent Batch Loss: 0.006\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 69 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.006\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3e358de98fce4fd196159d1f2d8e7d63",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 70\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6aa6cffe657c4165a0d1ea97cc57c934",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 70 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.014\n",
                        "\tMost Recent Batch Loss: 0.014\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 70 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.007\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f371c44c032340a9b770a288967820d4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 71\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1ebb6d01a01d4df59330c3ccad948beb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 71 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.013\n",
                        "\tMost Recent Batch Loss: 0.013\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 71 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.007\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3ff969fa63d84323aed3a71fd770ec99",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 72\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "65b497d63bbf413fa6c7b412bcf5d5bd",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 72 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.010\n",
                        "\tMost Recent Batch Loss: 0.010\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 72 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.004\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "dfebf3a7f629445b83d2803cb110411b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 73\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f3a4224f4141485c96e645868098ceb7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 73 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.003\n",
                        "\tMost Recent Batch Loss: 0.003\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 73 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.008\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "35ddc2b01ab84efc9f74ab34468e0b8d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 74\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8b766a198fdd44e1a0a69cd95d2a1354",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 74 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.004\n",
                        "\tMost Recent Batch Loss: 0.004\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 74 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.006\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "aa090082c7e14c0ba219837d4d8e6548",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 75\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "23d0f245e06146658be81ac20de92a8e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 75 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.007\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 75 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.005\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0da394ae42bb479e851df1ce1d63b2c6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 76\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6ebd18825cfe4176bb3824cb31f7be59",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 76 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.018\n",
                        "\tMost Recent Batch Loss: 0.018\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 76 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.006\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9806642754e74fcdb6b9ab9e4c3149e9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 77\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4f2c9b05bb8e439c9e927773834ed473",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 77 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.011\n",
                        "\tMost Recent Batch Loss: 0.011\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 77 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.006\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "dc4e5959b0624bb7a413d68483e3c610",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 78\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "60bc2c13dc854427b43116b4e3baf75f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 78 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.003\n",
                        "\tMost Recent Batch Loss: 0.003\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 78 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.003\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "868bf39ba25042c2b29832db0ba4b0d3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 79\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0643727e335e46a78dfb8d56bf2967cb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 79 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.009\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 79 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.007\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "def07c1a07b440d3a8a2e970adbd15e7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 80\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "aa0d6556e5d540fea1b14f3eee1ab634",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 80 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.008\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 80 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.006\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "61651b38a62b48ce988bb61c88924747",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 81\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4058a36eb5444bf1a4004c81270aba3f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 81 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.003\n",
                        "\tMost Recent Batch Loss: 0.003\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 81 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.003\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f3de455aff2745279062cfcc65080107",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 82\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8a6d89a522f04408b7f053c8459df568",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 82 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.014\n",
                        "\tMost Recent Batch Loss: 0.014\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 82 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.020\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3e42bbc3fa544bc5b209b69b91a713e4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 83\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "99dc833223fc4abdaa5a4d48d6b6e105",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 83 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.007\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 83 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.013\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "53c9f2bdf5074308834f60dde5a06ef8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 84\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d069713e95a04938b89cb1e66f34a964",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 84 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.012\n",
                        "\tMost Recent Batch Loss: 0.012\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 84 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.005\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "52bf52f1ed1d4f81b7d175bba313089f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 85\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "82c846e5fdb34f46af34e4ceb09edee9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 85 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.004\n",
                        "\tMost Recent Batch Loss: 0.004\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 85 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.009\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0d5bc4e5687e442ba428f7427688b8f6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 86\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3bd7da016db0400f821b0b30ae417c66",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 86 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.008\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 86 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.006\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bf43744bab90410e9fdc7f4e1095cbe8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 87\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8f56f6c6566341159d8c290e7dfd1293",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 87 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.007\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 87 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.007\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "eeba28d5f4094a328d391406ad2bce44",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 88\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "905a0e25c5224f2cad5692d8f6f8cce1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 88 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.005\n",
                        "\tMost Recent Batch Loss: 0.005\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 88 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.011\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7e4439f0713645bea31cffc1c76c43b2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 89\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "edb66b65d2124b47b6987e681d50ae34",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 89 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.009\n",
                        "\tMost Recent Batch Loss: 0.009\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 89 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.015\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bae49031ff624548bef8724637e7335c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 90\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9aaf08c5cfe642029d476840fc7d910f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 90 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.003\n",
                        "\tMost Recent Batch Loss: 0.003\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 90 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.004\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ac2f654b800f431982eb8c72dd53ec53",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 91\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c3e23db3e5604a64b1bd1d55547d752c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 91 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.012\n",
                        "\tMost Recent Batch Loss: 0.012\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 91 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.004\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "16c8bd14c6c14a7bbd6e78a45da1ba2d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 92\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c657f79223fd4e4590fde53e90abe404",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 92 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.004\n",
                        "\tMost Recent Batch Loss: 0.004\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 92 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.004\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "eb7063d1654e4170bf60c60fb3922330",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 93\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "785114d22ece45aeaa9ecb998e399921",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 93 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.008\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 93 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.007\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "93e90d64b50a40ca9ef0f8979eb178e3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 94\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5b2e0b08416b4594b500dafd6fb399ba",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 94 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.006\n",
                        "\tMost Recent Batch Loss: 0.006\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 94 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.007\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3f0f9d2bf8c642ef8a0f1a644a8868ef",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 95\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e1d9a9dc96b5452a9c998945513d8bc4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 95 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.003\n",
                        "\tMost Recent Batch Loss: 0.003\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 95 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.008\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "29d8abe609fc48149d08d941d395b2e1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 96\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1ff584d7d5bb4ef3bcc6b27001621d6f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 96 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.005\n",
                        "\tMost Recent Batch Loss: 0.005\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 96 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.006\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "831d760f8984426ab4768814e8bdbc2c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 97\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "743ef19c2def40e791374b2a4d21d537",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 97 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.005\n",
                        "\tMost Recent Batch Loss: 0.005\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 97 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.005\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5c851e727a7744ddba8b9deec801221e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 98\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d67e8b49c7da41208f9fca5ef55290e3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 98 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.012\n",
                        "\tMost Recent Batch Loss: 0.012\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 98 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.008\n",
                        "\tMost Recent Batch Loss: 0.008\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "323a7052b7e74250a8ad1b5f4ba3f99a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training Epoch 99\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "faecac72d29242609fa5bc0fdb29e74c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/113 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 99 [batch 0/113, 0.00%] \n",
                        "\tEpoch Running Average Loss: 0.004\n",
                        "\tMost Recent Batch Loss: 0.004\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2304) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2336) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2208) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch: 99 [batch 100/113, 88.50%] \n",
                        "\tEpoch Running Average Loss: 0.007\n",
                        "\tMost Recent Batch Loss: 0.008\n",
                        "\n",
                        "Validation.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "79631b2350e840098dfb604538c4f1bb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Best Model Appears at Epoch 21 with Validation score 0.757.\n"
                    ]
                }
            ],
            "source": [
                "%%capture --no-stdout --no-display\n",
                "# Uncomment the line above to silence outputs from this cell\n",
                "\n",
                "num_workers = 10\n",
                "model.train(\n",
                "    balanced_train_df,\n",
                "    val_df,\n",
                "    epochs=100, #change to more later\n",
                "    batch_size=64,\n",
                "    log_interval=100,  # log progress every 100 batches\n",
                "    num_workers=num_workers,  # parallelized cpu tasks for preprocessing\n",
                "    wandb_session=wandb_session,\n",
                "    save_interval=1,  # save checkpoint every 10 epochs\n",
                "    save_path=checkpoint_folder,  # location to save checkpoints\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2b498f89-d856-45b5-bfe6-b9e94e603ada",
            "metadata": {},
            "source": [
                "Once this is finished running, you have trained the CNN. \n",
                "\n",
                "To generate predictions on audio files using the CNN, use the `.predict()` method of the CNN object. Here, we apply a sigmoid activation layer which maps the CNN's outputs (all real numbers) to a 0-1 range. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "6bde9106",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d9df63ad3e70421f84724ecaccbdc725",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/4 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2272) too large for available bit count (2200)\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
                        "  return data.pin_memory(device)\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
                        "  return data.pin_memory(device)\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1804] error: dequantization failed!\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
                        "  return data.pin_memory(device)\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
                        "  return data.pin_memory(device)\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "[src/libmpg123/layer3.c:INT123_do_layer3():1774] error: part2_3_length (2400) too large for available bit count (2200)\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
                        "  return data.pin_memory(device)\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
                        "  return data.pin_memory(device)\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/audio.py:1465: UserWarning: Failed to load metadata: argument of type 'NoneType' is not iterable. Metadata will be None\n",
                        "  warnings.warn(f\"Failed to load metadata: {exc}. Metadata will be None\")\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.pin_memory() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:46.)\n",
                        "  return data.pin_memory(device)\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py:57: DeprecationWarning: The argument 'device' of Tensor.is_pinned() is deprecated. Please do not pass this argument. (Triggered internally at /pytorch/aten/src/ATen/native/Memory.cpp:31.)\n",
                        "  return data.pin_memory(device)\n",
                        "/home/dah238/miniconda3/envs/davis/lib/python3.10/site-packages/opensoundscape/ml/safe_dataset.py:134: UserWarning: There were 1 sample(s) that raised errors and were skipped.\n",
                        "  warnings.warn(msg)\n"
                    ]
                }
            ],
            "source": [
                "scores_df = model.predict(val_df, \n",
                "                          activation_layer=\"sigmoid\",\n",
                "                          batch_size=128\n",
                "                          )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "bef9fb77",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[8.51429105e-01, 5.89138530e-02, 1.15398318e-03, ...,\n",
                            "        1.12943540e-04, 1.07984764e-04, 1.11620720e-04],\n",
                            "       [3.57150957e-02, 6.99437514e-04, 1.75428977e-06, ...,\n",
                            "        6.14962337e-05, 1.21283243e-04, 8.69997893e-05],\n",
                            "       [9.99628425e-01, 3.76564058e-05, 9.81461853e-05, ...,\n",
                            "        1.19806435e-04, 6.21489817e-05, 9.10046583e-06],\n",
                            "       ...,\n",
                            "       [1.66199903e-03, 6.69554397e-02, 5.11319027e-04, ...,\n",
                            "        8.88543218e-05, 3.40043152e-05, 1.52641428e-06],\n",
                            "       [9.98303890e-01, 2.98118423e-04, 1.40662683e-04, ...,\n",
                            "        2.46264525e-02, 2.83991627e-04, 1.60234587e-04],\n",
                            "       [2.98044197e-05, 1.17107913e-04, 1.24878379e-05, ...,\n",
                            "        3.50147711e-05, 9.56414442e-06, 2.68660806e-04]], dtype=float32)"
                        ]
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "val_df.head\n",
                "scores_df.values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "e2b5765f",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'map': tensor(0.5975), 'auroc': tensor(0.7205)}"
                        ]
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model.eval(val_df.values,scores_df.values)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b1946c1f",
            "metadata": {},
            "source": [
                "We don't expect this CNN to actually be good at classifying sounds, since we only trained it with a few examples and for a couple epochs. We'd want to train with hundreds of examples per class for 10-100 epochs as a starting point for training a useful model. \n",
                "\n",
                "For guidance on how to use machine learning classifiers, see the Classifieres 101 Guide on opensoundscape.org and the tutorial on predicting with pre-trained CNNs.\n",
                "\n",
                "\n",
                "**Clean up:** Run the following cell to delete the files created in this tutorial. However, these files are used in other tutorials, so you may wish not to delete them just yet."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "davis",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
